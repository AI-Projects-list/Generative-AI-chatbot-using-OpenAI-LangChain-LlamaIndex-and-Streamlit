# ğŸ§  Generative AI Demo Project

This project demonstrates a **Generative AI App** that uses:
- **OpenAI GPT-4 API** for text generation
- **LangChain** for orchestration and prompt handling
- **LlamaIndex** for document indexing and RAG (Retrieval-Augmented Generation)
- **Streamlit** as a user interface
- **FAISS** for vector database

## ğŸ¯ Use Case
Build a chatbot that can:
- Answer questions based on uploaded documents (PDF/TXT)
- Perform generative responses to user input
- Log conversation history

---

## ğŸ”§ Project Structure

```
â”œâ”€â”€ app.py                  # Streamlit UI
â”œâ”€â”€ chatbot.py              # Core logic (LangChain, OpenAI, RAG)
â”œâ”€â”€ data/
â”‚   â””â”€â”€ sample.pdf          # Sample document for indexing
â”œâ”€â”€ utils.py                # Helper functions
â”œâ”€â”€ requirements.txt        # Dependencies
â”œâ”€â”€ .env                    # OpenAI key
â””â”€â”€ README.md
```

---

## âš™ï¸ Installation

```bash
git clone https://github.com/your-org/genai-chatbot.git
cd genai-chatbot
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate on Windows
pip install -r requirements.txt
```

Set your OpenAI key in `.env`:
```env
OPENAI_API_KEY=sk-xxxxx
```

---

## ğŸš€ Run the App

```bash
streamlit run app.py
```

Open [http://localhost:8501](http://localhost:8501) to start using the chatbot.

---

## ğŸ§± Key Components

### âœ… LangChain
- Used to structure the chatbot chain
- Handles conversation memory
- Supports tools (e.g., search or database)

### âœ… LlamaIndex (Optional)
- Indexes and retrieves content from uploaded PDFs or TXT files
- Integrated with FAISS for fast retrieval

### âœ… OpenAI GPT-4
- Generates responses
- Can be replaced with other models (Claude, Gemini, Ollama)

### âœ… Streamlit
- Fast web UI
- Easy to extend and deploy

---

## ğŸ“¦ Sample Code Snippet

```python
from langchain.chat_models import ChatOpenAI
from langchain.chains import ConversationalRetrievalChain
from llama_index import SimpleDirectoryReader, GPTVectorStoreIndex

# Load documents
reader = SimpleDirectoryReader('data')
docs = reader.load_data()
index = GPTVectorStoreIndex.from_documents(docs)

# Create chatbot
llm = ChatOpenAI(model_name="gpt-4")
chain = ConversationalRetrievalChain.from_llm(llm, retriever=index.as_retriever())
```

---

## ğŸ“Š Example Query

> User: What is this document about?

> AI: Based on the document, it covers ...

---

## â˜ï¸ Deployment
- For public access, deploy using:
  - **Render.com** (free for small apps)
  - **Streamlit Cloud**
  - **Docker + Vercel** (with FastAPI backend)

---

## ğŸ” Security Tips
- Sanitize user input to prevent prompt injection
- Limit token usage with max_tokens
- Log API usage with timestamps

---

## ğŸ“š References
- [LangChain Docs](https://docs.langchain.com)
- [LlamaIndex Docs](https://gpt-index.readthedocs.io/)
- [OpenAI API](https://platform.openai.com/docs)
- [Streamlit](https://streamlit.io)

---

## ğŸ¤– Next Steps
- Add support for voice input (e.g., with Whisper API)
- Use Ollama or LLaMA3 for local inference
- Connect to a database for persistent chat memory

---


